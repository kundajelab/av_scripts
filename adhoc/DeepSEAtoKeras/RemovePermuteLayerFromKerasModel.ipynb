{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                  *  /users/avanti/anaconda3\r\n",
      "fixed_env                /users/avanti/anaconda3/envs/fixed_env\r\n",
      "py2diabeticretinopathy     /users/avanti/anaconda3/envs/py2diabeticretinopathy\r\n",
      "py35                     /users/avanti/anaconda3/envs/py35\r\n",
      "py376                    /users/avanti/anaconda3/envs/py376\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/avanti/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 13:05:25.784074 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0905 13:05:25.810347 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0905 13:05:25.897318 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0905 13:05:25.898430 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0905 13:05:25.907634 140417144153920 deprecation.py:506] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0905 13:05:25.937011 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0905 13:05:31.886348 140417144153920 deprecation_wrapper.py:119] From /users/avanti/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1993, 320)         10560     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1993, 320)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1986, 320)         819520    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1986, 320)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1986, 320)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 496, 320)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 489, 480)          1229280   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 489, 480)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 482, 480)          1843680   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 482, 480)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 482, 480)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 120, 480)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 113, 640)          2458240   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 113, 640)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 106, 640)          3277440   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 106, 640)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 106, 640)          0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 640, 106)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67840)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2003)              135885523 \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2003)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2002)              4012008   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2002)              0         \n",
      "=================================================================\n",
      "Total params: 149,536,251\n",
      "Trainable params: 149,536,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/avanti/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"/mnt/lab_data2/avanti/ExPecto/resources/deepseabeluga_keras.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(Conv1D(kernel_size=8, filters=320, input_shape=(2000,4)))\n",
    "new_model.layers[0].set_weights(model.layers[0].get_weights())\n",
    "#We copy over remaining layers up until the Permute layer, which we are\n",
    "# going to get rid of the need for (I had the Permute layer to cope\n",
    "# with the fact that the original pytorch model was in a 'channels first'\n",
    "# format, but Keras is 'channels last', and the weights of the pytorch Dense\n",
    "# layer were such that it was expecting the output of the conv layer to\n",
    "# be in a 'channels first' format - however, we will deal with this by\n",
    "# just rearranging the weights of the Dense layer, since we have to modify\n",
    "# those weights anyway).\n",
    "for layer in model.layers[1:16]:\n",
    "  layer_config = layer.get_config()\n",
    "  del layer_config['name'] #let the name be autogenerated to avoid collisions\n",
    "  new_layer = type(layer)(**layer_config)\n",
    "  if (len(layer.get_weights()) > 0):\n",
    "      new_layer.build(layer.input_shape)\n",
    "  new_layer.set_weights(layer.get_weights())\n",
    "  new_model.add(new_layer)\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(2003,name=\"altereddense\"))\n",
    "for layer in model.layers[20:]:\n",
    "  layer_config = layer.get_config()\n",
    "  del layer_config['name'] #let the name be autogenerated to avoid collisions\n",
    "  new_layer = type(layer)(**layer_config)\n",
    "  if (len(layer.get_weights()) > 0):\n",
    "      new_layer.build(layer.input_shape)\n",
    "  new_layer.set_weights(layer.get_weights())\n",
    "  new_model.add(new_layer)\n",
    "\n",
    "first_dense_layer_weights, first_dense_layer_biases = model.layers[19].get_weights()\n",
    "#These next lines alter the weights of the dense layer so that the whole model\n",
    "# will work on an input of length 400bp\n",
    "#While porting the weights over, we also get rid of the need for the Permute\n",
    "# layer by applying the 'transpose' on the weights. The truncation of 50:56 is\n",
    "# what gets the model to work on an input of length 400bp\n",
    "new_first_dense_layer_weights = first_dense_layer_weights.reshape((640,106,2003))[:,:,:].transpose((1,0,2)).reshape((640*106,2003))\n",
    "new_model.layers[17].set_weights([new_first_dense_layer_weights, first_dense_layer_biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_inputs = np.random.RandomState(1).rand(20,2000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = new_model.predict(random_inputs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds = model.predict(random_inputs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01404548, 0.00812003, 0.03995261, ..., 0.0014019 , 0.00124151,\n",
       "        0.00027382],\n",
       "       [0.01368925, 0.00793654, 0.03913379, ..., 0.00138   , 0.00120765,\n",
       "        0.00026703],\n",
       "       [0.01411042, 0.00824639, 0.04028746, ..., 0.00141218, 0.00125223,\n",
       "        0.00027704],\n",
       "       ...,\n",
       "       [0.01376671, 0.00773171, 0.03907946, ..., 0.00139257, 0.00119784,\n",
       "        0.00026679],\n",
       "       [0.01378527, 0.0078198 , 0.03910923, ..., 0.00137195, 0.00119868,\n",
       "        0.00026551],\n",
       "       [0.01403785, 0.00804397, 0.03988525, ..., 0.00137761, 0.00121778,\n",
       "        0.00026941]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01404554, 0.00812   , 0.03995261, ..., 0.00140196, 0.00124151,\n",
       "        0.00027382],\n",
       "       [0.01368925, 0.00793654, 0.03913385, ..., 0.00138   , 0.00120765,\n",
       "        0.00026694],\n",
       "       [0.01411036, 0.00824639, 0.04028741, ..., 0.00141218, 0.00125223,\n",
       "        0.00027713],\n",
       "       ...,\n",
       "       [0.01376671, 0.00773171, 0.03907952, ..., 0.0013926 , 0.00119784,\n",
       "        0.0002667 ],\n",
       "       [0.0137853 , 0.0078198 , 0.03910923, ..., 0.00137192, 0.00119859,\n",
       "        0.00026551],\n",
       "       [0.01403782, 0.00804397, 0.03988525, ..., 0.00137761, 0.00121778,\n",
       "        0.00026935]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7881393e-07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(old_preds-new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1993, 320)         10560     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1993, 320)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1986, 320)         819520    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1986, 320)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1986, 320)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 496, 320)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 489, 480)          1229280   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 489, 480)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 482, 480)          1843680   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 482, 480)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 482, 480)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 120, 480)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 113, 640)          2458240   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 113, 640)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 106, 640)          3277440   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 106, 640)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67840)             0         \n",
      "_________________________________________________________________\n",
      "altereddense (Dense)         (None, 2003)              135885523 \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2003)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2002)              4012008   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2002)              0         \n",
      "=================================================================\n",
      "Total params: 149,536,251\n",
      "Trainable params: 149,536,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"/mnt/lab_data2/avanti/ExPecto/resources/deepseabeluga_keras_nopermutelayer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
