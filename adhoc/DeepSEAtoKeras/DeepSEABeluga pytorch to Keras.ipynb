{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the DeepSEA Beluga model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.serialization import load_lua\n",
    "\n",
    "#The model is downloaded from\n",
    "# wget http://deepsea.princeton.edu/media/code/expecto/resources.tar.gz\n",
    "pytorch_model = load_lua('/home/ashrikumar/scratch/ashrikumar/models/ExPecto/resources/deepsea.beluga.2002.cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (0) -> (1) -> (2) -> output]\n",
       "  (0): nn.Sequential {\n",
       "    [input -> (0) -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> output]\n",
       "    (0): nn.SpatialConvolution(4 -> 320, 1x8)\n",
       "    (1): nn.ReLU\n",
       "    (2): nn.SpatialConvolution(320 -> 320, 1x8)\n",
       "    (3): nn.ReLU\n",
       "    (4): nn.Dropout(0.2000)\n",
       "    (5): nn.SpatialMaxPooling(1x4, 1, 4)\n",
       "    (6): nn.SpatialConvolution(320 -> 480, 1x8)\n",
       "    (7): nn.ReLU\n",
       "    (8): nn.SpatialConvolution(480 -> 480, 1x8)\n",
       "    (9): nn.ReLU\n",
       "    (10): nn.Dropout(0.2000)\n",
       "    (11): nn.SpatialMaxPooling(1x4, 1, 4)\n",
       "    (12): nn.SpatialConvolution(480 -> 640, 1x8)\n",
       "    (13): nn.ReLU\n",
       "    (14): nn.SpatialConvolution(640 -> 640, 1x8)\n",
       "    (15): nn.ReLU\n",
       "  }\n",
       "  (1): nn.Sequential {\n",
       "    [input -> (0) -> (1) -> (2) -> (3) -> (4) -> output]\n",
       "    (0): nn.Dropout(0.5000)\n",
       "    (1): nn.Reshape(67840)\n",
       "    (2): nn.Linear(67840 -> 2003)\n",
       "    (3): nn.ReLU\n",
       "    (4): nn.Linear(2003 -> 2002)\n",
       "  }\n",
       "  (2): nn.Sigmoid\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a keras model with the right architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashrikumar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "keras_model = keras.models.Sequential()\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=320, kernel_size=8,\n",
    "            strides=1, padding=\"valid\",\n",
    "            batch_input_shape=(None, 2000, 4)))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=320, kernel_size=8,\n",
    "            strides=1, padding=\"valid\",\n",
    "            batch_input_shape=(None, 1000, 4)))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.core.Dropout(0.2))\n",
    "keras_model.add(keras.layers.pooling.MaxPooling1D(\n",
    "           pool_size=4, strides=4, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=480, kernel_size=8,\n",
    "            strides=1, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=480, kernel_size=8,\n",
    "            strides=1, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.core.Dropout(0.2))\n",
    "keras_model.add(keras.layers.pooling.MaxPooling1D(\n",
    "           pool_size=4, strides=4, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=640, kernel_size=8,\n",
    "            strides=1, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.convolutional.Conv1D(\n",
    "            filters=640, kernel_size=8,\n",
    "            strides=1, padding=\"valid\"))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.core.Dropout(0.5))\n",
    "keras_model.add(keras.layers.core.Permute((2,1)))\n",
    "keras_model.add(keras.layers.core.Flatten())\n",
    "keras_model.add(keras.layers.core.Dense(2003))\n",
    "keras_model.add(keras.layers.Activation(\"relu\"))\n",
    "keras_model.add(keras.layers.core.Dense(2002))\n",
    "keras_model.add(keras.layers.Activation(\"sigmoid\"))\n",
    "keras_model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port the DeepSEA weights over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv1_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[0].weight\n",
    "                           .detach().cpu().numpy())[:,[0,2,1,3]]\n",
    "                           .transpose((2,1,0)))\n",
    "conv1_bias = (pytorch_model.modules[0].modules[0].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[0].set_weights([conv1_weight, conv1_bias])\n",
    "\n",
    "\n",
    "conv2_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[2].weight\n",
    "                           .detach().cpu().numpy())\n",
    "                           .transpose((2,1,0)))\n",
    "conv2_bias = (pytorch_model.modules[0].modules[2].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[2].set_weights([conv2_weight, conv2_bias])\n",
    "\n",
    "\n",
    "conv3_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[6].weight\n",
    "                           .detach().cpu().numpy())\n",
    "                           .transpose((2,1,0)))\n",
    "conv3_bias = (pytorch_model.modules[0].modules[6].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[6].set_weights([conv3_weight, conv3_bias])\n",
    "\n",
    "\n",
    "conv4_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[8].weight\n",
    "                           .detach().cpu().numpy())\n",
    "                           .transpose((2,1,0)))\n",
    "conv4_bias = (pytorch_model.modules[0].modules[8].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[8].set_weights([conv4_weight, conv4_bias])\n",
    "\n",
    "\n",
    "conv5_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[12].weight\n",
    "                           .detach().cpu().numpy())\n",
    "                           .transpose((2,1,0)))\n",
    "conv5_bias = (pytorch_model.modules[0].modules[12].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[12].set_weights([conv5_weight, conv5_bias])\n",
    "\n",
    "\n",
    "conv6_weight = (np.squeeze(pytorch_model.modules[0]\n",
    "                           .modules[14].weight\n",
    "                           .detach().cpu().numpy())\n",
    "                           .transpose((2,1,0)))\n",
    "conv6_bias = (pytorch_model.modules[0].modules[14].bias\n",
    "                           .detach().cpu().numpy())\n",
    "keras_model.layers[14].set_weights([conv6_weight, conv6_bias])\n",
    "\n",
    "\n",
    "dense1_weight = (np.squeeze(pytorch_model.modules[1].modules[2].weight\n",
    "                            .detach().cpu().numpy())).transpose((1,0))    \n",
    "dense1_bias = (pytorch_model.modules[1].modules[2].bias\n",
    "                            .detach().cpu().numpy())\n",
    "keras_model.layers[19].set_weights([dense1_weight, dense1_bias])\n",
    "\n",
    "\n",
    "dense2_weight = (np.squeeze(pytorch_model.modules[1].modules[4].weight\n",
    "                            .detach().cpu().numpy())).transpose((1,0))   \n",
    "dense2_bias = (pytorch_model.modules[1].modules[4].bias\n",
    "                            .detach().cpu().numpy())\n",
    "keras_model.layers[21].set_weights([dense2_weight, dense2_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save(\"deepseabeluga_keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the conversion is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.serialization import load_lua\n",
    "\n",
    "pytorch_model = load_lua('/home/ashrikumar/scratch/ashrikumar/models/ExPecto/resources/deepsea.beluga.2002.cpu')\n",
    "\n",
    "np.random.seed(1)\n",
    "dummy_data = np.random.random((10,4,2000,1))\n",
    "#one-hot encode it\n",
    "dummy_data = (dummy_data==np.max(dummy_data,axis=1)[:,None,:,:]).astype(\"float32\")\n",
    "\n",
    "pytorch_predictions = (pytorch_model.forward(torch.from_numpy(dummy_data))\n",
    "                       .detach().cpu().numpy())\n",
    "\n",
    "np.save(\"pytorch_preds.npy\", pytorch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel may crash if both pytorch and keras are run in same session, so good to reload before running cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashrikumar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ashrikumar/anaconda2/lib/python2.7/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.556511e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "np.random.seed(1)\n",
    "dummy_data = np.random.random((10,4,2000,1))\n",
    "#one-hot encode it\n",
    "dummy_data = (dummy_data==np.max(dummy_data,axis=1)[:,None,:,:]).astype(\"float32\")\n",
    "\n",
    "keras_model = load_model(\"deepseabeluga_keras.h5\")\n",
    "pytorch_predictions = np.load(\"pytorch_preds.npy\")\n",
    "keras_predictions = keras_model.predict(dummy_data.squeeze().transpose(0,2,1)[:,:,[0,2,1,3]])\n",
    "max_diff = np.max(np.abs(pytorch_predictions-keras_predictions))\n",
    "print(max_diff)\n",
    "assert max_diff < 10**-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
